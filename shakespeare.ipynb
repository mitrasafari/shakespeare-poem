{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = 'G:\\\\datasets\\\\shakespeare.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open(path_file,'r',encoding=\"utf8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d buriest thy conten\n"
     ]
    }
   ],
   "source": [
    "print(text[500:520])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '>',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '|',\n",
       " '}']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '\\n')\n",
      "(1, ' ')\n",
      "(2, '!')\n",
      "(3, '\"')\n",
      "(4, '&')\n",
      "(5, \"'\")\n",
      "(6, '(')\n",
      "(7, ')')\n",
      "(8, ',')\n",
      "(9, '-')\n",
      "(10, '.')\n",
      "(11, '0')\n",
      "(12, '1')\n",
      "(13, '2')\n",
      "(14, '3')\n",
      "(15, '4')\n",
      "(16, '5')\n",
      "(17, '6')\n",
      "(18, '7')\n",
      "(19, '8')\n",
      "(20, '9')\n",
      "(21, ':')\n",
      "(22, ';')\n",
      "(23, '<')\n",
      "(24, '>')\n",
      "(25, '?')\n",
      "(26, 'A')\n",
      "(27, 'B')\n",
      "(28, 'C')\n",
      "(29, 'D')\n",
      "(30, 'E')\n",
      "(31, 'F')\n",
      "(32, 'G')\n",
      "(33, 'H')\n",
      "(34, 'I')\n",
      "(35, 'J')\n",
      "(36, 'K')\n",
      "(37, 'L')\n",
      "(38, 'M')\n",
      "(39, 'N')\n",
      "(40, 'O')\n",
      "(41, 'P')\n",
      "(42, 'Q')\n",
      "(43, 'R')\n",
      "(44, 'S')\n",
      "(45, 'T')\n",
      "(46, 'U')\n",
      "(47, 'V')\n",
      "(48, 'W')\n",
      "(49, 'X')\n",
      "(50, 'Y')\n",
      "(51, 'Z')\n",
      "(52, '[')\n",
      "(53, ']')\n",
      "(54, '_')\n",
      "(55, '`')\n",
      "(56, 'a')\n",
      "(57, 'b')\n",
      "(58, 'c')\n",
      "(59, 'd')\n",
      "(60, 'e')\n",
      "(61, 'f')\n",
      "(62, 'g')\n",
      "(63, 'h')\n",
      "(64, 'i')\n",
      "(65, 'j')\n",
      "(66, 'k')\n",
      "(67, 'l')\n",
      "(68, 'm')\n",
      "(69, 'n')\n",
      "(70, 'o')\n",
      "(71, 'p')\n",
      "(72, 'q')\n",
      "(73, 'r')\n",
      "(74, 's')\n",
      "(75, 't')\n",
      "(76, 'u')\n",
      "(77, 'v')\n",
      "(78, 'w')\n",
      "(79, 'x')\n",
      "(80, 'y')\n",
      "(81, 'z')\n",
      "(82, '|')\n",
      "(83, '}')\n"
     ]
    }
   ],
   "source": [
    "for pair in enumerate(vocab):\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_ind = {char:ind for ind,char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'\\n': 0,\n",
       " ' ': 1,\n",
       " '!': 2,\n",
       " '\"': 3,\n",
       " '&': 4,\n",
       " \"'\": 5,\n",
       " '(': 6,\n",
       " ')': 7,\n",
       " ',': 8,\n",
       " '-': 9,\n",
       " '.': 10,\n",
       " '0': 11,\n",
       " '1': 12,\n",
       " '2': 13,\n",
       " '3': 14,\n",
       " '4': 15,\n",
       " '5': 16,\n",
       " '6': 17,\n",
       " '7': 18,\n",
       " '8': 19,\n",
       " '9': 20,\n",
       " ':': 21,\n",
       " ';': 22,\n",
       " '<': 23,\n",
       " '>': 24,\n",
       " '?': 25,\n",
       " 'A': 26,\n",
       " 'B': 27,\n",
       " 'C': 28,\n",
       " 'D': 29,\n",
       " 'E': 30,\n",
       " 'F': 31,\n",
       " 'G': 32,\n",
       " 'H': 33,\n",
       " 'I': 34,\n",
       " 'J': 35,\n",
       " 'K': 36,\n",
       " 'L': 37,\n",
       " 'M': 38,\n",
       " 'N': 39,\n",
       " 'O': 40,\n",
       " 'P': 41,\n",
       " 'Q': 42,\n",
       " 'R': 43,\n",
       " 'S': 44,\n",
       " 'T': 45,\n",
       " 'U': 46,\n",
       " 'V': 47,\n",
       " 'W': 48,\n",
       " 'X': 49,\n",
       " 'Y': 50,\n",
       " 'Z': 51,\n",
       " '[': 52,\n",
       " ']': 53,\n",
       " '_': 54,\n",
       " '`': 55,\n",
       " 'a': 56,\n",
       " 'b': 57,\n",
       " 'c': 58,\n",
       " 'd': 59,\n",
       " 'e': 60,\n",
       " 'f': 61,\n",
       " 'g': 62,\n",
       " 'h': 63,\n",
       " 'i': 64,\n",
       " 'j': 65,\n",
       " 'k': 66,\n",
       " 'l': 67,\n",
       " 'm': 68,\n",
       " 'n': 69,\n",
       " 'o': 70,\n",
       " 'p': 71,\n",
       " 'q': 72,\n",
       " 'r': 73,\n",
       " 's': 74,\n",
       " 't': 75,\n",
       " 'u': 76,\n",
       " 'v': 77,\n",
       " 'w': 78,\n",
       " 'x': 79,\n",
       " 'y': 80,\n",
       " 'z': 81,\n",
       " '|': 82,\n",
       " '}': 83}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind['H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_to_char = np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[39]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = np.array([char_to_ind[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5447699,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
       "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
       "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
       "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
       "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
       "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
       "       75,  1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63,\n",
       "       70, 76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60,\n",
       "       56, 74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,\n",
       "        1, 63, 60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1,\n",
       "       63, 64, 74,  1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,\n",
       "        1, 75, 63, 70, 76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1,\n",
       "       75, 70,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62,\n",
       "       63, 75,  1, 60, 80, 60, 74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74,\n",
       "       75,  1, 75, 63, 80,  1, 67, 64, 62, 63, 75,  5, 74,  1, 61, 67, 56,\n",
       "       68, 60,  1, 78, 64, 75, 63,  1, 74, 60, 67, 61,  9, 74, 76, 57, 74,\n",
       "       75, 56, 69, 75, 64, 56, 67,  1, 61, 76, 60, 67,  8,  0,  1,  1, 38,\n",
       "       56, 66, 64, 69, 62,  1, 56,  1, 61, 56, 68, 64, 69, 60,  1, 78, 63,\n",
       "       60, 73, 60,  1, 56, 57, 76, 69, 59, 56, 69, 58, 60,  1, 67, 64, 60,\n",
       "       74,  8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67, 61,  1, 75, 63, 80,\n",
       "        1, 61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1, 74, 78, 60, 60,\n",
       "       75,  1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76, 60, 67, 21,\n",
       "        0,  1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73, 75,  1,\n",
       "       69, 70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 61,\n",
       "       73, 60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1,\n",
       "       26, 69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75,\n",
       "       70,  1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69,\n",
       "       62,  8,  0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,\n",
       "        1, 70, 78, 69,  1, 57, 76])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = '''From fairest creatures we desire increase,\n",
    "  That thereby beauty's rose might never die,\n",
    "  But as the riper should by time decease'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_num_seq = len(text) // (seq_len+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45022"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(seq_len+1 , drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seq_targets(seq):\n",
    "    input_txt = seq[:-1] #hello my nam\n",
    "    target_txt = seq[1:] #ello mya name\n",
    "    return input_txt,target_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
      "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
      "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
      " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
      " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But\n",
      "\n",
      "\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
      "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
      " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
      " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
      "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But \n"
     ]
    }
   ],
   "source": [
    "for input_txt,target_txt in dataset.take(1):\n",
    "    print(input_txt.numpy())\n",
    "    print(\"\".join(ind_to_char[input_txt.numpy()]))\n",
    "    print(\"\\n\")\n",
    "    print(target_txt.numpy())\n",
    "    print(\"\".join(ind_to_char[target_txt.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(120,), dtype=int32, numpy=\n",
      "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
      "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
      "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
      "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
      "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
      "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
      "       75])>, <tf.Tensor: shape=(120,), dtype=int32, numpy=\n",
      "array([ 1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "        1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64, 73,\n",
      "       60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,  1,\n",
      "       59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,  0,\n",
      "        1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57, 60,\n",
      "       56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63, 75,\n",
      "        1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76, 75,\n",
      "        1])>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_size = 10000\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(128, 120), dtype=int32, numpy=\n",
      "array([[ 1, 27, 73, ..., 75,  1, 78],\n",
      "       [70, 74, 60, ..., 80, 10,  0],\n",
      "       [75,  1, 71, ..., 56, 75,  1],\n",
      "       ...,\n",
      "       [63, 60,  1, ..., 56, 76, 75],\n",
      "       [79, 64, 75, ...,  1, 34, 74],\n",
      "       [ 1, 63, 56, ..., 64, 70, 69]])>, <tf.Tensor: shape=(128, 120), dtype=int32, numpy=\n",
      "array([[27, 73, 64, ...,  1, 78, 56],\n",
      "       [74, 60,  1, ..., 10,  0,  1],\n",
      "       [ 1, 71, 73, ..., 75,  1, 34],\n",
      "       ...,\n",
      "       [60,  1, 61, ..., 76, 75, 63],\n",
      "       [64, 75,  1, ..., 34, 74,  1],\n",
      "       [63, 56, 77, ..., 70, 69,  1]])>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_neurons = 1026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true,y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true,y_pred,from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,GRU,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size,embed_dim,rnn_neurons,batch_size):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size,embed_dim,batch_input_shape=[batch_size, None]))\n",
    "    model.add(GRU(rnn_neurons,return_sequences=True,\n",
    "                 stateful=True,recurrent_initializer='glorot_uniform'))                                                         \n",
    "    model.add(Dense(vocab_size))\n",
    "    \n",
    "    model.compile('adam' ,loss = sparse_cat_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(vocab_size= vocab_size,\n",
    "                     embed_dim = embed_dim,\n",
    "                     rnn_neurons=rnn_neurons,\n",
    "                     batch_size=batch_size)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (128, None, 64)           5376      \n",
      "_________________________________________________________________\n",
      "gru_2 (GRU)                  (128, None, 1026)         3361176   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (128, None, 84)           86268     \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch,target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(128, 120), dtype=int32, numpy=\n",
      "array([[73,  8,  0, ..., 74, 63, 56],\n",
      "       [74,  1, 80, ..., 75,  8,  0],\n",
      "       [34, 46, 44, ..., 70, 71, 67],\n",
      "       ...,\n",
      "       [74, 60,  1, ...,  2,  0,  1],\n",
      "       [ 1, 57, 60, ..., 63, 70, 76],\n",
      "       [74, 75,  1, ..., 62, 73, 70]])>, <tf.Tensor: shape=(128, 120), dtype=int32, numpy=\n",
      "array([[ 8,  0,  1, ..., 63, 56, 67],\n",
      "       [ 1, 80, 70, ...,  8,  0,  1],\n",
      "       [46, 44, 10, ..., 71, 67, 60],\n",
      "       ...,\n",
      "       [60,  1, 75, ...,  0,  1,  1],\n",
      "       [57, 60, 74, ..., 70, 76,  1],\n",
      "       [75,  1, 64, ..., 73, 70, 78]])>)\n"
     ]
    }
   ],
   "source": [
    "for i in dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 120), dtype=int32, numpy=\n",
       "array([[75, 70,  1, ..., 68,  5, 74],\n",
       "       [70, 61,  1, ..., 62, 56, 77],\n",
       "       [ 8,  1, 74, ...,  1,  1,  1],\n",
       "       ...,\n",
       "       [73, 73, 76, ..., 59,  1, 78],\n",
       "       [60, 80,  1, ...,  1, 63, 56],\n",
       "       [68, 80, 74, ...,  2,  1, 34]])>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example_batch_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = tf.random.categorical(example_batch_predictions[0],num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(120, 1), dtype=int64, numpy=\n",
       "array([[69],\n",
       "       [37],\n",
       "       [45],\n",
       "       [81],\n",
       "       [58],\n",
       "       [51],\n",
       "       [27],\n",
       "       [33],\n",
       "       [59],\n",
       "       [ 0],\n",
       "       [58],\n",
       "       [25],\n",
       "       [44],\n",
       "       [16],\n",
       "       [52],\n",
       "       [20],\n",
       "       [51],\n",
       "       [64],\n",
       "       [83],\n",
       "       [59],\n",
       "       [77],\n",
       "       [70],\n",
       "       [17],\n",
       "       [17],\n",
       "       [29],\n",
       "       [70],\n",
       "       [15],\n",
       "       [78],\n",
       "       [79],\n",
       "       [69],\n",
       "       [ 6],\n",
       "       [50],\n",
       "       [58],\n",
       "       [14],\n",
       "       [38],\n",
       "       [22],\n",
       "       [60],\n",
       "       [61],\n",
       "       [80],\n",
       "       [62],\n",
       "       [39],\n",
       "       [32],\n",
       "       [26],\n",
       "       [23],\n",
       "       [67],\n",
       "       [81],\n",
       "       [22],\n",
       "       [35],\n",
       "       [69],\n",
       "       [64],\n",
       "       [58],\n",
       "       [12],\n",
       "       [28],\n",
       "       [ 9],\n",
       "       [14],\n",
       "       [57],\n",
       "       [48],\n",
       "       [37],\n",
       "       [53],\n",
       "       [15],\n",
       "       [24],\n",
       "       [78],\n",
       "       [34],\n",
       "       [82],\n",
       "       [42],\n",
       "       [52],\n",
       "       [32],\n",
       "       [22],\n",
       "       [25],\n",
       "       [80],\n",
       "       [73],\n",
       "       [54],\n",
       "       [41],\n",
       "       [15],\n",
       "       [47],\n",
       "       [12],\n",
       "       [79],\n",
       "       [63],\n",
       "       [ 5],\n",
       "       [66],\n",
       "       [53],\n",
       "       [ 6],\n",
       "       [46],\n",
       "       [37],\n",
       "       [66],\n",
       "       [55],\n",
       "       [25],\n",
       "       [45],\n",
       "       [33],\n",
       "       [67],\n",
       "       [74],\n",
       "       [83],\n",
       "       [57],\n",
       "       [42],\n",
       "       [58],\n",
       "       [50],\n",
       "       [67],\n",
       "       [42],\n",
       "       [11],\n",
       "       [83],\n",
       "       [19],\n",
       "       [ 6],\n",
       "       [39],\n",
       "       [34],\n",
       "       [18],\n",
       "       [76],\n",
       "       [76],\n",
       "       [56],\n",
       "       [16],\n",
       "       [13],\n",
       "       [63],\n",
       "       [25],\n",
       "       [70],\n",
       "       [75],\n",
       "       [64],\n",
       "       [43],\n",
       "       [23],\n",
       "       [33],\n",
       "       [32],\n",
       "       [56]], dtype=int64)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_indices = tf.squeeze(sample_indices,axis=1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([69, 37, 45, 81, 58, 51, 27, 33, 59,  0, 58, 25, 44, 16, 52, 20, 51,\n",
       "       64, 83, 59, 77, 70, 17, 17, 29, 70, 15, 78, 79, 69,  6, 50, 58, 14,\n",
       "       38, 22, 60, 61, 80, 62, 39, 32, 26, 23, 67, 81, 22, 35, 69, 64, 58,\n",
       "       12, 28,  9, 14, 57, 48, 37, 53, 15, 24, 78, 34, 82, 42, 52, 32, 22,\n",
       "       25, 80, 73, 54, 41, 15, 47, 12, 79, 63,  5, 66, 53,  6, 46, 37, 66,\n",
       "       55, 25, 45, 33, 67, 74, 83, 57, 42, 58, 50, 67, 42, 11, 83, 19,  6,\n",
       "       39, 34, 18, 76, 76, 56, 16, 13, 63, 25, 70, 75, 64, 43, 23, 33, 32,\n",
       "       56], dtype=int64)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#model.fit(dataset,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(vocab_size,embed_dim,rnn_neurons,batch_size=1)\n",
    "\n",
    "model.load_weights('shakespear_model.h5')\n",
    "\n",
    "model.build(tf.TensorShape([1,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 64)             5376      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1026)           3361176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 84)             86268     \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model,start_seed,gen_size=500,temp=1.0):\n",
    "    num_generate = gen_size\n",
    "    \n",
    "    input_eval = [char_to_ind[s] for s in start_seed]\n",
    "    \n",
    "    input_eval = tf.expand_dims(input_eval,0)\n",
    "    \n",
    "    text_generated = []\n",
    "    \n",
    "    temperature = temp\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        \n",
    "        predictions = tf.squeeze(predictions,0)\n",
    "        \n",
    "        predictions = predictions/temperature\n",
    "        \n",
    "        predictions_id = tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
    "        \n",
    "        input_eval = tf.expand_dims([predictions_id],0)\n",
    "        \n",
    "        text_generated.append(ind_to_char[predictions_id])\n",
    "        \n",
    "    return (start_seed + \"\".join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mitrance;\n",
      "    Bear! Where's my consext, 'the gentleman here?\n",
      "DROMIO OF EPHESUS. Patience, good madam.\n",
      "    How long have  well shall be forsworn.\n",
      "    O this allain and mistress hast thou bark'st.\n",
      "    That shall I bring thee that that did the Duke,\n",
      "    Rescae Edmund? Let thy virtue love in my\n",
      "    kinsme, 'twas Suffolk's house; let the trumpet; therefore, 'tis Tribute, the King's, and\n",
      "    that thou seem our poison in his hand, I am a time\n",
      "    Do there where ease myself so easily as\n",
      "    Warwick, although she thence,\n",
      "    As is thy tongue and will, and wept to-\n",
      "    His eyes do hare the heir of unconstant death,\n",
      "    And live-cheat, set it thus, and this shall be proud;\n",
      "    I name not one of our master.\n",
      "  LAUNCE. If the deceive not desire it too much clapp'd from death.          Exit  \n",
      "  LOUNCES. Here is my hand, sir; she is working for the child, horte poisons.\n",
      "    My lord, welcome, sir; the nois me this last cause\n",
      "    To give her to my foes, so again,\n",
      "  I keep perfecteth that sanct unto the Emper\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"mitra\",gen_size=1000))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('shakespear_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
